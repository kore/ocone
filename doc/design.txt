=====================
oCone design document
=====================

The name
========

The name oCone derivates from "Open Content Network" and shows the goal of
oCone to build up a network of free and open available content.

The goal
========

The worlds evolution mainly bases on information, or content. The internet
shows a fantastic infrastructure to publish content and make it available for
everyone in the world, but it has some draw backs.

Content is normally published using HTML (or XHTML) which only describes
visible formats and does not structure the content in a senseful semantical
way. Even there are a lot of initiatives to change this it will take some time
to update / transform all content. There are some persons who say that they are 
a lot of companies and persons who do not even want their content to be really
readable.

The infrastructure of the internet is pretty stable but the number of users
and potential hits on a single website caused by famous news sites requires
expensive infrastructures to serve those. This is something only big 
institutions or comapanies can afford.

oCone tries to solve this by building a peer to peer network, where each peer
can grab content from the web (if allowed), transform it into semantic XML and
offer it to the other peers. In a network each peer will cache the requested
contents and will reduce the load on the requested sites this way. With enough
capacity in the peers caches oCone will even be able to mirror complete
webpages for use in networks not connected with the internet, or serve content
for websites which are offline during the request.

Client design
=============

Transforming content
--------------------

To grab and transform content from webpages we need a turing complete language
to transform (X)HTML, PDF, Text and other formats to semantic XML. As a bonus
the language should have good, build in, capabilities to work with XML.

In theory the client could serve a lot of language bindings for this task, but
the scripts need to be spread between the clients, so that we should
concentrate on one tested language. Executing foreign scripts in your personal
environment may result in security risks if the language is not known for good
sandboxing of the scripts.

ECMAScripts (some may only know the JavaScript implementations) has proven
good in all of the above points and there are a lot of open source language
bindings for ECMAScript interpretors. The default language for transformation
scripts will be ECMAScript.

Authorizing scripts
-------------------

When scripts are distributed through a peer to peer network a user has to
trust the locally executed scripts beyond the sandbox. Users mistrust may be
caused by political incorrect contents, or scripts abusing the power given by
a peer to peer network.

To ensure that all users who request contents are also contributing to the
network, users may only request data from scripts which they allow to be
executed locally.

A user should be able to have fine grained control over the local scripts, so
that he should have several options for each script:
- Allow execution
- Allow caching of aggregated contents
- Allow forwarding of requests

Not every user wants to perform such fine grained control over possible
scripts, so that there should be common lists of "good" scripts to help users
configuring their clients.

Content caching
---------------

Caching of requested content is viable for the network to work. If contents
would not be cached a grown network could cause DOS attacks on bad performing
websites.

Each client has a configured amount of diskspace available for cached content.
A script defines the cache strategies for content, which may be a combination 
of time to live and directives to handle the content if the website is not
reachable any more. If the the size of the cached content is bigger then the
configured cache size old content will be purged.

On an request the client itself will check if he has the content available. If
this is not the case the client will start a breadth-first search on all known
peers with a limited depth. If the depth limit is reached and no cached
content could be found the client will rerequest the content from the website
and update its cache. He may notify the previously contacted peers that he has
the requested content available.

Communication
-------------

The client should be able to run as a deamon with no user interaction to
optimally perform on servers and can be up 24/7. Optionally it should be
possible to configure the client using a webinterface or a normal GUI. To
reach this goal we get three levels of communication:

.. image:: connections.svg
   :alt:   oCone communication structure

1. Peer to peer communication

   This communication level describes the interaction of different oCone
   clients for interchaning data, sending cache requests and sharing scripts.
   The protocol itself is described in the section `Peer to peer protocol`__.

2. GUI communication

   The GUI needs access to the oCone clients / deamons data to display the
   clients status and to configure the client.

   Presumeably we do not need to describe another network protocol here but
   can interact using a local command line interface. The output of the CLI
   programs need of course be parseable (perhaps optionally XML) and offer
   access to all features of the deamon.

3. Deamon <-> client communication

   The clients are not oCone clients in this diagram, but random programs
   using the oCone network and caching abilities to request content.

   Example for this use case:

   A user wants to use his browser request wikipedia contents using the oCone 
   network. He enters a URL like ocone://en.wikipedia/oCone in the URL bar of
   his browser. The browser now contacts the local oCone deamon which checks
   his cache for the requested information and forwards the requests to other
   peers in the network if the data was not locally available. In the meantime
   the administrator of the oCone deamon could watch the status of the request
   using the GUI, or CLI tools. If the browser gets the resulting XML he could
   display it using a defined set of XSLT and CSS, or just print the raw XML.

The protocol
============

Peer to peer protocol
---------------------

Client protocol
---------------

The client protocol should be easy to implement for random clients. Nearly
each programming language / development environment has abilities to send HTTP
requests, so that we will use a REST interface for the client to deamon
communication. To enable this the ocone deamon need to start a HTTP server,
but we of course do not want to use the common port 80, because we do not want
to enforce the deamon to run as root. The default port the HTTP server will
run on is port 8023 (yet unassigned), but this should of course be 
configurable.

The client should understand URL of the following scheme:

	ocone://server[:port]/script[/parameter[...]]

This very simplified grammar follows for its elements the URI stadard.

The "server" specifies the hostname or IP the ocone deamon runs on, and the
the "port" defaults to the above mentioned 8023, but can be overwritten. The
"script" defines a unique script name referencing the script to fetch the data
with optional additional parameters provided to the script.

The server simply returns a XML document, either containing a error, or the
result of the script. The following RelaxNG defines the structure of the
scripts result.

..
  element ocone {
    (
	  element header {
	    element source { text }, # Content source url
	    element authors {
	      element author {
	        attribute email { text }?, # Mail address
	        { text } # Name
		  }
	    },
	    element license { text },
	    element status {
	 	  element script {
		    attribute name { text }, # Name of script
		    element parameters {
			  element parameter { text }*
		    }?,
		    element run { text } # Unix timestamp
		  }
	    }
	  },
	  element content { empty }
	  # Content contains the XML from the script response from another
	  # namespace
    ) | (
	  element error {
	  	attribute id { text }, # Error identifier
		element message { text }, # Error message text
		element information { text }? # Additional error information
	  }
	)
  }

The content element defines a new default namespace for its childs which
contain the actual content generated by the script.

Caching strategy
================

Cache options
-------------

Cache purging / overwriting algorithm
-------------------------------------

Technical problems / Open questions
===================================

NAT & Firewalls
---------------

Using IPv4, NAT is a quite usual setup for a lot of clients. NAT without
forwarding the right ports to the IP the client runs on, or firewall rules
declining the access to the port, prevent the client to be contacted from the
net. Ho do we deal with clients which can access other clients, but are not 
accessible from the web?

One slution could be to establish permanent connections with a decent amount
of known peers and only communicate over those established connections. The
addresses of those impaired clients should not be forwarded to other peers,
because only the impaired client itself can establish connections.

Script distribution & script versioning
---------------------------------------

We need to share scripts through the peer to peer network with user
notification to authorize new scripts, or new script versions. On the other
hand we want to provide script white lists to make it easier for user to allow
groups of well known scripts to be executed in his local environment. Those
script lists could include the scripts, so that they should not need to be
shared through the network, but are directly included.

Evil clients
------------

Since the protocol is documented and the (default) client will be open source
it is easy to write your own client using the protocol and try abusing the 
network. This sections should list possible attacks and strategies to act 
against them.

As no client needs to authentificate there is no way to identify a client.
Everything, like version string, signed messages, etc. could be faked by just
copying those parts from the official client.

1. Injecting spam, or other broken content

   A client could pretend to have content cached and serve completely
   different content instead. This could either be spam, or just plain wrong
   content. This only affects cached contents, because othwerwise the client
   will fetch the data itself.
   
   This problem couzld be resolved by comparing the return of multiple clients
   by multiple hashs of the content and use the results with the most hits.
   This could of course also be manipulated, but should be nearly impossible
   in big networks, and can be combined with IP / Client blacklist distributed
   by common servers.

   Without an authorized client it is impossible to really verify a script
   response as correct.

2. Serving malicious scripts
   
   Malicious scripts can be detected by storing several hash sums for the
   script in the whitelist and comparing the script against those hashes.

3. Exceeding clients memory with too many requests

   Each client has a queue with the requests by other clients he wants to
   serve. This queue could be exceeded and consume a lot of open connections
   and memory by high amounts of requests. If the queue of a client exceeds a
   certain limit the client could response with messages indicating that it is
   currectly unavailable for more requests.

   To prevent from clients always sending service unavailable messages, the
   other clients could store ratings for their peers, and send requests to
   those clients more seldom and schedule their requests with a lower
   priority. This should also help balancing the requests in the network.

4. Only requesting, but no caching / fetching / forwarding
   
   The default client will ensure, that the user can only request contents
   from scripts he offers caching, fetching and forwarding for. A custom
   client could of course bypass this.

   The only way to detect such misbehaviour is gathering statistics for every
   known peer and reduce the clients schedule priority on bad behaviour. There
   is no way to proof detect some clients misbehaviour. In a big enough
   network the count of those misshapen clients should always be low enough to
   be safely ignored.

